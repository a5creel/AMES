\documentclass{article}

\usepackage[paper=letterpaper,margin=2.5cm]{geometry} % Set Margins

%% Math and math fonts
\usepackage{amsmath, amsthm, amssymb, amsfonts}
\usepackage{bbm} % for \mathbbm{1}

% date
\usepackage[nodayofweek]{datetime}

% Color
\usepackage{color, xcolor}

% Misc
\usepackage{environ}  % \collect@body in asmmath
\usepackage{graphicx} % \includegraphics options
\usepackage{mdframed} % text boxes
\usepackage{indentfirst} % Indent first paragraph after section header
\usepackage[shortlabels]{enumitem} % Control enumerate items with [(a)]
\usepackage{comment} % Comments
\usepackage{fancyhdr} % Headers and footers

% Tables
\usepackage{array}

% Sub-figures and figure placement
\usepackage{caption}
\usepackage{subcaption}
\usepackage{float} 

% Graphing
\usepackage{pgfplots}
\pgfplotsset{compat=1.17}
\usepackage{tikz}

% Title Placement
\usepackage{titling}
\setlength{\droptitle}{-6em}

%set indent to 
\setlength{\parindent}{0pt}

% Hyper refs
\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    urlcolor  = blue,
    filecolor=magenta,      
    urlcolor=blue,
    citecolor = blue,
    anchorcolor = blue
}

% % Citation management
\usepackage{natbib}
\bibliographystyle{abbrvnat}
\setcitestyle{authordate,open={(},close={)}}

\pagestyle{fancy}

\usepackage[paper=letterpaper,margin=2.5cm]{geometry} % Set Margins

%% Math and math fonts
\usepackage{amsmath, amsthm, amssymb, amsfonts}
\usepackage{bbm} % for \mathbbm{1}

% date
\usepackage[nodayofweek]{datetime}

% Color
\usepackage{color, xcolor}

% Misc
\usepackage{environ}  % \collect@body in asmmath
\usepackage{graphicx} % \includegraphics options
\usepackage{mdframed} % text boxes
\usepackage{indentfirst} % Indent first paragraph after section header
\usepackage{comment} % Comments
\usepackage{fancyhdr} % Headers and footers

% Tables
\usepackage{array}

% Sub-figures and figure placement
\usepackage{caption}
% \usepackage{subcaption}
\usepackage{float} 

% Graphing
\usepackage{pgfplots}
\pgfplotsset{compat=1.17}
\usepackage{tikz}

% Title Placement
\usepackage{titling}
\setlength{\droptitle}{-6em}

%set indent to 
\setlength{\parindent}{0pt}

% Hyper refs
\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    urlcolor  = blue,
    filecolor=magenta,      
    urlcolor=blue,
    citecolor = blue,
    anchorcolor = blue
}

% % Citation management
\usepackage{natbib}
\bibliographystyle{abbrvnat}
\setcitestyle{authordate,open={(},close={)}}

\newcolumntype{M}{>{$}c<{$}} % Define a new column type for math mode


% ----------------------------------------
% TITLE
% ----------------------------------------

\pagestyle{fancy}

\lhead{Creel}
\chead{Linar Algebra, cont}
\rhead{AMES}

\title{AMES Class Notes -- Week 9, Monday: Linear Algebra, cont}
\author{Andie Creel}

\begin{document}
\maketitle

\section{Squaring matrices}

Consider a matrix $\underset{N \times 1}{V}$ that you'd like to square. 

\begin{align}
    V^2 &= \underset{1 \times N} V^T  \underset{N \times 1}V\\
    &= \underset{ 1 \times 1} Z
\end{align}

Sometimes you'll have a weighting matrix, $\underset{ N \times N}M$

\begin{align}
   \underset{1 \times N} V^T \underset{ N \times N}M  \underset{N\times 1}V = \underset{ 1 \times 1}  Z   
\end{align}


\section{Idempotent matrix}
Defn: A matrix that when squared equals itself 
\begin{align}
    Z^T Z = Z
\end{align}

This property means that applying the matrix operation twice (or any number of times) has the same effect as applying it once.

\section{Kronecker product}

You see this is computer algorithms and data management problems. It's a common trick. It's technically a "tenser" operation. A tenser is a $3^+$D matrix object. \\

The \textbf{Kronecker product} is an operation that takes two matrices and produces a larger matrix by multiplying each element of the first matrix by the entire second matrix. If \( A \) is an \( m \times n \) matrix and \( B \) is a \( p \times q \) matrix, then the Kronecker product \( A \otimes B \) is an \( mp \times nq \) block matrix, where each entry \( a_{ij} \) in \( A \) is replaced by the block \( a_{ij} B \).

\subsection*{Definition}
For matrices \( A = \begin{bmatrix} a_{11} & a_{12} \\ a_{21} & a_{22} \end{bmatrix} \) and \( B = \begin{bmatrix} b_{11} & b_{12} \\ b_{21} & b_{22} \end{bmatrix} \), the Kronecker product \( A \otimes B \) is:

\[
A \otimes B = \begin{bmatrix} a_{11}B & a_{12}B \\ a_{21}B & a_{22}B \end{bmatrix} = \begin{bmatrix} a_{11}b_{11} & a_{11}b_{12} & a_{12}b_{11} & a_{12}b_{12} \\ a_{11}b_{21} & a_{11}b_{22} & a_{12}b_{21} & a_{12}b_{22} \\ a_{21}b_{11} & a_{21}b_{12} & a_{22}b_{11} & a_{22}b_{12} \\ a_{21}b_{21} & a_{21}b_{22} & a_{22}b_{21} & a_{22}b_{22} \end{bmatrix}
\]

The Kronecker product is widely used in signal processing, control theory, and other fields where constructing block matrices is essential.

\section{Trace of a Matrix}

The \textbf{trace} of a matrix is the sum of the elements along its \textit{main diagonal} (the diagonal that runs from the top left to the bottom right of the matrix).

\subsection*{Definition}

For a square matrix \( A \) of size \( n \times n \):
\[
A = \begin{bmatrix} a_{11} & a_{12} & \cdots & a_{1n} \\ a_{21} & a_{22} & \cdots & a_{2n} \\ \vdots & \vdots & \ddots & \vdots \\ a_{n1} & a_{n2} & \cdots & a_{nn} \end{bmatrix},
\]
the trace of \( A \), denoted as \( \text{tr}(A) \), is given by:
\[
\text{tr}(A) = a_{11} + a_{22} + \cdots + a_{nn} = \sum_{i=1}^n a_{ii}.
\]

\section{Rank of a Matrix}

The \textbf{rank} of a matrix is the dimension of the \textit{column space} (or \textit{row space}) of the matrix. Intuitively, it represents the maximum number of linearly independent columns (or rows) in the matrix.

For a matrix \( A \):
\begin{itemize}
    \item The \textit{column space} of \( A \) consists of all possible linear combinations of its columns.
    \item The rank tells us the number of independent directions in the space spanned by the columns.
\end{itemize}

\subsection*{Properties of Rank}
\begin{enumerate}
    \item \textbf{Range}: The rank of an \( m \times n \) matrix \( A \) is at most \( \min(m, n) \).
    \item \textbf{Full Rank}: 
    \begin{itemize}
        \item If the rank of \( A \) is equal to \( n \) (for an \( m \times n \) matrix), then \( A \) is said to have \textit{full column rank}, meaning all columns are linearly independent. 
        \item Note: the dimensions of a matrix are always give rows by columns, which is why we know that $n$ is referring to the number of columns.
        \item If the rank of \( A \) is equal to \( m \), then \( A \) has \textit{full row rank}.
    \end{itemize}
\end{enumerate}

The rank is fundamental in linear algebra, especially for solving linear systems, determining invertibility, and performing dimensionality reduction in applications such as data science.



\section{Linear regression}
Consider the equation estimating equation 
\begin{align}
    y = a + bx + cz + \epsilon \label{reg_eqn}
\end{align}

We can rewrite this as

\begin{align}
    \underset{N \times 1} Y = \underset{N \times K } X 
                              \underset{K \times 1} \beta +  \underset{ N \times 1} \epsilon\\
\end{align} 
where 
\begin{align}
    \beta = \begin{bmatrix}
        a\\
        b\\
        c
    \end{bmatrix} \label{params}\\
    X = \begin{bmatrix}
        1 & x_1& z_1\\
        1 & x_2 & z_2\\
        \vdots & ...
    \end{bmatrix}\\
    Y = \begin{bmatrix}
        y_1\\
        y_2\\
        \vdots
    \end{bmatrix}
\end{align}

\textbf{Goal:} Solve for $\beta$ by minimizing the sum of square errors. \\

Solve for the error term:
\begin{align}
    \underset{N \times 1} Y - \underset{N \times K}{X \beta} = \underset{N \times 1} \epsilon
\end{align}

Square the error term:
\begin{align}
    \underset{1 \times N} \epsilon^T  \underset{N \times 1}\epsilon &= 
        \underset{1 \times N}{(Y - X \beta)^T} \underset{N \times 1}{(Y - X \beta)} \\
    &= \underset{1 \times N}Y^T \underset{N \times 1} Y - \underset{1 \times K} \beta^T \underset{K \times N} X^T \underset{N \times 1} Y - \underset{1 \times N} Y^T \underset{N \times K} X \underset{K \times 1}\beta + \underset{1 \times K}\beta^T \underset{K \times N}X^T \underset{N \times K}X \underset{K \times 1}\beta\\
    &= \underset{1 \times 1}{Y^T Y} - \underset{1 \times 1}{2 \beta^T X^T Y} + \underset{1 \times 1}{\beta^T X^T X \beta}
\end{align}

The squared error term is a scalar $\underset{(1 \times 1)}{\epsilon^T \epsilon}$. \\

We want to find the $\beta$ that minimizes the sum of squared errors. To do so, take derivative of squared error wrt to $\beta^T$ and set equal to zero, then solve for $\beta$. 

\begin{align}
    \frac{\partial \epsilon^T  \epsilon }{ \partial \beta} = 0 - \underset{K \times 1}{2X^T Y} + \underset{K \times 1}{2 X^T X \beta} = 0 \implies \\
    2X^T Y = 2 X^T X \beta \implies \\
    \beta = {(X^T X)}^{-1} X^T Y
\end{align}

Where ${(X^T X)}^{-1}$ is an inversion (because we cannot divide matrices). \\

We have solved for $\beta$, which is a vector of all the parameters that we saw in equation \ref{reg_eqn} (look at equation \ref{params}). Remember, the first element of $\beta$ is the intercept \textit{because} the first column of $\mathbf{X}$ is all 1s (rather than any variable). The column of 1s is important and forces the first element of $\beta$ to be the intercept. 

\section{Life cycle assessment example}

Let's consider and input output table (Ag, Transportation, Manufactured)
\begin{align}
    A = \underset{ 3 \times 3}{\begin{bmatrix}
         & A & T & M \\
         A \\
         T\\
         M
    \end{bmatrix}}
\end{align}

And our final demand (the demand for goods by consumers) 
\begin{align}
    d = \underset{3 \times 1}{\begin{bmatrix}
        A \\
        T\\
        M
    \end{bmatrix}}
\end{align}

Total amount of goods $X$ is, 
\begin{align}
    \underset{3 \times 1}{X} = \underset{3 \times 3}{A} \underset{3 \times 1}{X} + \underset{3 \times 1}{d}
 \end{align}
Solve for X by multiplying with the identity matrix 
\begin{align}
    \underset{3 \times 3}{I} X - AX = d\\
    (I - A) X = d\\
    \implies (I - A)^{-1}d = X
\end{align}

Total amount of goods is different than final demand because we need input good for the final good. A bunch of intermediate products are required to make a computer. 


\section{R and Excel}
Watch the video! Couple of notes \\
- to invert a matrix in R you use the solve() command


\end{document}